{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers\n",
        "!pip install datasets"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BLxgxmCcvtur",
        "outputId": "a12abe0c-af8b-4ff0-b169-c2aea121fe9a"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.40.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.13.4)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.19.3 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.20.3)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.25.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (24.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2023.12.25)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.31.0)\n",
            "Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.19.1)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.2)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.19.3->transformers) (2023.6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.19.3->transformers) (4.11.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2024.2.2)\n",
            "Collecting datasets\n",
            "  Downloading datasets-2.19.0-py3-none-any.whl (542 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m542.0/542.0 kB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from datasets) (3.13.4)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from datasets) (1.25.2)\n",
            "Requirement already satisfied: pyarrow>=12.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (14.0.2)\n",
            "Requirement already satisfied: pyarrow-hotfix in /usr/local/lib/python3.10/dist-packages (from datasets) (0.6)\n",
            "Collecting dill<0.3.9,>=0.3.0 (from datasets)\n",
            "  Downloading dill-0.3.8-py3-none-any.whl (116 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m7.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (2.0.3)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (2.31.0)\n",
            "Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (4.66.2)\n",
            "Collecting xxhash (from datasets)\n",
            "  Downloading xxhash-3.4.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.1/194.1 kB\u001b[0m \u001b[31m9.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting multiprocess (from datasets)\n",
            "  Downloading multiprocess-0.70.16-py310-none-any.whl (134 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m9.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: fsspec[http]<=2024.3.1,>=2023.1.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (2023.6.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets) (3.9.5)\n",
            "Collecting huggingface-hub>=0.21.2 (from datasets)\n",
            "  Downloading huggingface_hub-0.22.2-py3-none-any.whl (388 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m388.9/388.9 kB\u001b[0m \u001b[31m10.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from datasets) (24.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (6.0.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.9.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (4.0.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.21.2->datasets) (4.11.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (2024.2.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2023.4)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\n",
            "Installing collected packages: xxhash, dill, multiprocess, huggingface-hub, datasets\n",
            "  Attempting uninstall: huggingface-hub\n",
            "    Found existing installation: huggingface-hub 0.20.3\n",
            "    Uninstalling huggingface-hub-0.20.3:\n",
            "      Successfully uninstalled huggingface-hub-0.20.3\n",
            "Successfully installed datasets-2.19.0 dill-0.3.8 huggingface-hub-0.22.2 multiprocess-0.70.16 xxhash-3.4.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gOE8aHfYvucw",
        "outputId": "186b8359-d6a6-4bb0-dcf5-ba87554f04e4"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "bLpRaw5w4Qqx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def load_data(data_file):\n",
        "    data = pd.read_csv(data_file)\n",
        "\n",
        "    # Extract pixels and emotions\n",
        "    pixels = data['pixels'].tolist()\n",
        "    emotions = pd.get_dummies(data['emotion']).to_numpy()\n",
        "\n",
        "    # Convert pixels to 3D array and add channel dimension\n",
        "    faces = np.array([np.fromstring(pixel_sequence, dtype=int, sep=' ').reshape(48, 48) for pixel_sequence in pixels])\n",
        "    faces = np.expand_dims(faces, axis=-1)\n",
        "\n",
        "    return faces, emotions"
      ],
      "metadata": {
        "id": "rkAjF_hRAKcZ"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "\n",
        "class CustomDataset(Dataset):\n",
        "    def __init__(self, data_file, reshape=True, dtype=torch.float32, seed=None):\n",
        "        self.data = pd.read_csv(data_file)\n",
        "        self.images = self.data['pixels'].apply(lambda x: np.fromstring(x, dtype=int, sep=' ').reshape(48, 48))\n",
        "        self.labels = self.data['emotion'].values.reshape(-1, 1)\n",
        "\n",
        "        if reshape:\n",
        "            self.images = np.stack(self.images).reshape(-1, 48*48)\n",
        "\n",
        "        self.labels = OneHotEncoder(sparse=False).fit_transform(self.labels)\n",
        "        self.images = torch.tensor(self.images, dtype=dtype) / 255.0\n",
        "        self.labels = torch.tensor(self.labels, dtype=dtype)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return self.images[idx], self.labels[idx]\n"
      ],
      "metadata": {
        "id": "FmeitdgZANyY"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import collections\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from tensorflow.python.framework import dtypes, random_seed\n",
        "\n",
        "train_data = \"/content/drive/MyDrive/CV/fer2013.csv\""
      ],
      "metadata": {
        "id": "iiRAiYnn0i6G"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = CustomDataset(train_data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uJuqEnP91PTg",
        "outputId": "ed473d45-1ca4-4e75-b4d4-bade7e264eb4"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/preprocessing/_encoders.py:868: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "train_ratio = 0.7\n",
        "val_ratio = 0.15\n",
        "test_ratio = 0.15\n",
        "\n",
        "# Splitting into training and remaining sets\n",
        "train_data, remaining_data = train_test_split(dataset, test_size=(val_ratio + test_ratio))\n",
        "\n",
        "# Splitting remaining set into validation and test sets\n",
        "val_data, test_data = train_test_split(remaining_data, test_size=test_ratio / (val_ratio + test_ratio))\n",
        "\n",
        "# Create DataLoader objects for training, validation, and test sets\n",
        "batch_size = 32\n",
        "train_loader = DataLoader(train_data, batch_size=batch_size, shuffle=True)\n",
        "val_loader = DataLoader(val_data, batch_size=batch_size, shuffle=False)\n",
        "test_loader = DataLoader(test_data, batch_size=batch_size, shuffle=False)\n"
      ],
      "metadata": {
        "id": "V2MAEaXz2IHm"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "6G8ne1pyeu4_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class CNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(CNN, self).__init__()\n",
        "\n",
        "        # First convolutional layer\n",
        "        self.conv1 = nn.Conv2d(1, 32, kernel_size=3, padding=1)\n",
        "        self.pool1 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "\n",
        "        # Second convolutional layer\n",
        "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, padding=1)\n",
        "        self.pool2 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "\n",
        "        # Third convolutional layer\n",
        "        self.conv3 = nn.Conv2d(64, 128, kernel_size=3, padding=1)\n",
        "\n",
        "        # Fourth convolutional layer\n",
        "        self.conv4 = nn.Conv2d(128, 128, kernel_size=3, padding=1)\n",
        "        self.pool3 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "\n",
        "        # LSTM layer\n",
        "        self.lstm = nn.LSTM(input_size=4608, hidden_size=128, num_layers=1, batch_first=True)\n",
        "\n",
        "        # Attention layer: compute correlation, attention distribution, and weighted average of hidden states\n",
        "        self.query_vector = nn.Parameter(torch.randn(128))  # Assume query vector is a learnable parameter\n",
        "\n",
        "        # Classification layer\n",
        "        self.classification_layer = nn.Linear(128, 7)  # 128 is the dimension of the context vector, 7 is the number of target classes\n",
        "        self.softmax = nn.Softmax(dim=1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Adjust input tensor shape\n",
        "        x = x.view(-1, 1, 48, 48)\n",
        "\n",
        "        # Convolutional and pooling layers\n",
        "        x = self.conv1(x)\n",
        "        x = self.pool1(x)\n",
        "        x = self.conv2(x)\n",
        "        x = self.pool2(x)\n",
        "        x = self.conv3(x)\n",
        "        x = self.conv4(x)\n",
        "        x = self.pool3(x)\n",
        "\n",
        "        # Flatten tensor for LSTM layer\n",
        "        x = x.view(x.size(0), -1)\n",
        "\n",
        "        # LSTM part\n",
        "        x, _ = self.lstm(x.unsqueeze(1))\n",
        "\n",
        "        # Attention layer\n",
        "        query_vector = self.query_vector.unsqueeze(0).expand(x.size(0), -1)\n",
        "        correlation_scores = torch.bmm(x, query_vector.unsqueeze(2)).squeeze(2)  # Dot product correlation\n",
        "        attention_distribution = F.softmax(correlation_scores, dim=1)  # Attention distribution\n",
        "        context_vector = torch.bmm(attention_distribution.unsqueeze(1), x).squeeze(1)  # Weighted average of hidden state\n",
        "\n",
        "        # Classification layer and softmax layer\n",
        "        x = self.classification_layer(context_vector)\n",
        "        x = self.softmax(x)\n",
        "\n",
        "        return x"
      ],
      "metadata": {
        "id": "0bjrQpUwHMVh"
      },
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = CNN()\n",
        "\n",
        "# Define the loss function and optimizer\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.0001, weight_decay=0.0001)\n",
        "\n",
        "# Define the device\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# Move model to the device\n",
        "model.to(device)\n",
        "\n",
        "# Training loop\n",
        "for epoch in range(num_epochs):\n",
        "    model.train()  # Set model to training mode\n",
        "    for images, labels in train_loader:\n",
        "        images, labels = images.to(device), labels.to(device)  # Move data to device\n",
        "        optimizer.zero_grad()  # Zero the gradients\n",
        "        outputs = model(images)  # Forward pass\n",
        "        loss = criterion(outputs, torch.argmax(labels, dim=1))  # Compute the loss\n",
        "        loss.backward()  # Backward pass\n",
        "        optimizer.step()  # Update the weights\n",
        "\n",
        "    # Validate the model\n",
        "    model.eval()  # Set model to evaluation mode\n",
        "    val_losses = []\n",
        "    val_predictions = []\n",
        "    val_true_labels = []\n",
        "    with torch.no_grad():\n",
        "        for images, labels in val_loader:\n",
        "            images, labels = images.to(device), labels.to(device)  # Move data to device\n",
        "            outputs = model(images)  # Forward pass\n",
        "            val_loss = criterion(outputs, torch.argmax(labels, dim=1))  # Compute the loss\n",
        "            val_losses.append(val_loss.item())\n",
        "            val_predictions.extend(torch.argmax(outputs, dim=1).cpu().numpy())\n",
        "            val_true_labels.extend(torch.argmax(labels, dim=1).cpu().numpy())\n",
        "\n",
        "    # Calculate validation accuracy\n",
        "    val_accuracy = accuracy_score(val_true_labels, val_predictions)\n",
        "\n",
        "    # Print epoch information\n",
        "    print(f'Epoch [{epoch+1}/{num_epochs}], '\n",
        "          f'Training Loss: {loss.item():.4f}, '\n",
        "          f'Validation Loss: {sum(val_losses)/len(val_losses)}, '\n",
        "          f'Validation Accuracy: {val_accuracy:.4f}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n2YTHu-Nj6jw",
        "outputId": "fa7f7b48-3936-4218-8e3f-a7c32ea8ca80"
      },
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/100], Training Loss: 1.9012, Validation Loss: 1.8685830203739144, Validation Accuracy: 0.2686\n",
            "Epoch [2/100], Training Loss: 1.8239, Validation Loss: 1.786194900083824, Validation Accuracy: 0.3836\n",
            "Epoch [3/100], Training Loss: 1.7412, Validation Loss: 1.7604738135309614, Validation Accuracy: 0.3959\n",
            "Epoch [4/100], Training Loss: 1.7592, Validation Loss: 1.740753511705342, Validation Accuracy: 0.4217\n",
            "Epoch [5/100], Training Loss: 1.7609, Validation Loss: 1.7338019609451294, Validation Accuracy: 0.4232\n",
            "Epoch [6/100], Training Loss: 1.7276, Validation Loss: 1.7238835653609779, Validation Accuracy: 0.4371\n",
            "Epoch [7/100], Training Loss: 1.5919, Validation Loss: 1.7156075126320653, Validation Accuracy: 0.4382\n",
            "Epoch [8/100], Training Loss: 1.7042, Validation Loss: 1.7071879319185337, Validation Accuracy: 0.4553\n",
            "Epoch [9/100], Training Loss: 1.6474, Validation Loss: 1.6999454519452428, Validation Accuracy: 0.4605\n",
            "Epoch [10/100], Training Loss: 1.6439, Validation Loss: 1.694844486445365, Validation Accuracy: 0.4728\n",
            "Epoch [11/100], Training Loss: 1.5898, Validation Loss: 1.688765964564487, Validation Accuracy: 0.4776\n",
            "Epoch [12/100], Training Loss: 1.6983, Validation Loss: 1.685035607518529, Validation Accuracy: 0.4782\n",
            "Epoch [13/100], Training Loss: 1.5358, Validation Loss: 1.6786448539361445, Validation Accuracy: 0.4858\n",
            "Epoch [14/100], Training Loss: 1.5091, Validation Loss: 1.674572548217322, Validation Accuracy: 0.4880\n",
            "Epoch [15/100], Training Loss: 1.6243, Validation Loss: 1.6692284296250202, Validation Accuracy: 0.4966\n",
            "Epoch [16/100], Training Loss: 1.6605, Validation Loss: 1.6637376532752133, Validation Accuracy: 0.5068\n",
            "Epoch [17/100], Training Loss: 1.6203, Validation Loss: 1.6610763425657735, Validation Accuracy: 0.5094\n",
            "Epoch [18/100], Training Loss: 1.5299, Validation Loss: 1.658927895613676, Validation Accuracy: 0.5046\n",
            "Epoch [19/100], Training Loss: 1.5611, Validation Loss: 1.6599231655075706, Validation Accuracy: 0.5092\n",
            "Epoch [20/100], Training Loss: 1.5085, Validation Loss: 1.65659171801347, Validation Accuracy: 0.5092\n",
            "Epoch [21/100], Training Loss: 1.5605, Validation Loss: 1.6524381404797706, Validation Accuracy: 0.5150\n",
            "Epoch [22/100], Training Loss: 1.3894, Validation Loss: 1.6532158096866494, Validation Accuracy: 0.5135\n",
            "Epoch [23/100], Training Loss: 1.5536, Validation Loss: 1.6495173400675758, Validation Accuracy: 0.5129\n",
            "Epoch [24/100], Training Loss: 1.5372, Validation Loss: 1.6481430361256797, Validation Accuracy: 0.5194\n",
            "Epoch [25/100], Training Loss: 1.4445, Validation Loss: 1.64652367668039, Validation Accuracy: 0.5198\n",
            "Epoch [26/100], Training Loss: 1.4845, Validation Loss: 1.645905382534456, Validation Accuracy: 0.5203\n",
            "Epoch [27/100], Training Loss: 1.3701, Validation Loss: 1.649667182617639, Validation Accuracy: 0.5153\n",
            "Epoch [28/100], Training Loss: 1.3851, Validation Loss: 1.6471364787344396, Validation Accuracy: 0.5176\n",
            "Epoch [29/100], Training Loss: 1.4453, Validation Loss: 1.6451200627716336, Validation Accuracy: 0.5194\n",
            "Epoch [30/100], Training Loss: 1.3974, Validation Loss: 1.6446596412263679, Validation Accuracy: 0.5205\n",
            "Epoch [31/100], Training Loss: 1.3907, Validation Loss: 1.643071481462061, Validation Accuracy: 0.5198\n",
            "Epoch [32/100], Training Loss: 1.3922, Validation Loss: 1.6418632741510515, Validation Accuracy: 0.5209\n",
            "Epoch [33/100], Training Loss: 1.4350, Validation Loss: 1.6433751413808066, Validation Accuracy: 0.5244\n",
            "Epoch [34/100], Training Loss: 1.4131, Validation Loss: 1.6440301385856944, Validation Accuracy: 0.5161\n",
            "Epoch [35/100], Training Loss: 1.3134, Validation Loss: 1.6423975984020347, Validation Accuracy: 0.5185\n",
            "Epoch [36/100], Training Loss: 1.2966, Validation Loss: 1.6416045843496831, Validation Accuracy: 0.5202\n",
            "Epoch [37/100], Training Loss: 1.4267, Validation Loss: 1.6388112214895396, Validation Accuracy: 0.5213\n",
            "Epoch [38/100], Training Loss: 1.2981, Validation Loss: 1.6383628880483865, Validation Accuracy: 0.5237\n",
            "Epoch [39/100], Training Loss: 1.4366, Validation Loss: 1.6406223012145453, Validation Accuracy: 0.5200\n",
            "Epoch [40/100], Training Loss: 1.2353, Validation Loss: 1.6461305018712784, Validation Accuracy: 0.5125\n",
            "Epoch [41/100], Training Loss: 1.2839, Validation Loss: 1.642548800220151, Validation Accuracy: 0.5192\n",
            "Epoch [42/100], Training Loss: 1.3393, Validation Loss: 1.6415834321072822, Validation Accuracy: 0.5172\n",
            "Epoch [43/100], Training Loss: 1.3409, Validation Loss: 1.6387532610865034, Validation Accuracy: 0.5252\n",
            "Epoch [44/100], Training Loss: 1.3275, Validation Loss: 1.6384227889529346, Validation Accuracy: 0.5192\n",
            "Epoch [45/100], Training Loss: 1.2369, Validation Loss: 1.6385233105992425, Validation Accuracy: 0.5239\n",
            "Epoch [46/100], Training Loss: 1.3162, Validation Loss: 1.6359731847717918, Validation Accuracy: 0.5242\n",
            "Epoch [47/100], Training Loss: 1.3198, Validation Loss: 1.6376405580509343, Validation Accuracy: 0.5222\n",
            "Epoch [48/100], Training Loss: 1.2585, Validation Loss: 1.6390840012646286, Validation Accuracy: 0.5192\n",
            "Epoch [49/100], Training Loss: 1.2394, Validation Loss: 1.6419710188927734, Validation Accuracy: 0.5194\n",
            "Epoch [50/100], Training Loss: 1.2732, Validation Loss: 1.641069690856708, Validation Accuracy: 0.5159\n",
            "Epoch [51/100], Training Loss: 1.2481, Validation Loss: 1.639067826891792, Validation Accuracy: 0.5209\n",
            "Epoch [52/100], Training Loss: 1.2525, Validation Loss: 1.6393502294664553, Validation Accuracy: 0.5190\n",
            "Epoch [53/100], Training Loss: 1.2942, Validation Loss: 1.643320088555827, Validation Accuracy: 0.5187\n",
            "Epoch [54/100], Training Loss: 1.3315, Validation Loss: 1.643699248866922, Validation Accuracy: 0.5138\n",
            "Epoch [55/100], Training Loss: 1.3039, Validation Loss: 1.637332658090535, Validation Accuracy: 0.5259\n",
            "Epoch [56/100], Training Loss: 1.1875, Validation Loss: 1.6393614048083154, Validation Accuracy: 0.5183\n",
            "Epoch [57/100], Training Loss: 1.2138, Validation Loss: 1.6370747914681067, Validation Accuracy: 0.5259\n",
            "Epoch [58/100], Training Loss: 1.2594, Validation Loss: 1.640778357460654, Validation Accuracy: 0.5161\n",
            "Epoch [59/100], Training Loss: 1.3274, Validation Loss: 1.6373879063058887, Validation Accuracy: 0.5218\n",
            "Epoch [60/100], Training Loss: 1.2714, Validation Loss: 1.6391406059265137, Validation Accuracy: 0.5190\n",
            "Epoch [61/100], Training Loss: 1.2823, Validation Loss: 1.6417788309458445, Validation Accuracy: 0.5161\n",
            "Epoch [62/100], Training Loss: 1.3044, Validation Loss: 1.6386578245275825, Validation Accuracy: 0.5146\n",
            "Epoch [63/100], Training Loss: 1.3369, Validation Loss: 1.6416068888274875, Validation Accuracy: 0.5179\n",
            "Epoch [64/100], Training Loss: 1.2891, Validation Loss: 1.6399549937107154, Validation Accuracy: 0.5196\n",
            "Epoch [65/100], Training Loss: 1.2581, Validation Loss: 1.6405444963443914, Validation Accuracy: 0.5179\n",
            "Epoch [66/100], Training Loss: 1.2365, Validation Loss: 1.6409651880433573, Validation Accuracy: 0.5146\n",
            "Epoch [67/100], Training Loss: 1.1885, Validation Loss: 1.6390879358765642, Validation Accuracy: 0.5203\n",
            "Epoch [68/100], Training Loss: 1.2410, Validation Loss: 1.6369530738458125, Validation Accuracy: 0.5215\n",
            "Epoch [69/100], Training Loss: 1.1700, Validation Loss: 1.638834470827904, Validation Accuracy: 0.5213\n",
            "Epoch [70/100], Training Loss: 1.2805, Validation Loss: 1.6364395477362639, Validation Accuracy: 0.5231\n",
            "Epoch [71/100], Training Loss: 1.2685, Validation Loss: 1.6363105886786646, Validation Accuracy: 0.5216\n",
            "Epoch [72/100], Training Loss: 1.2318, Validation Loss: 1.6351928541646201, Validation Accuracy: 0.5216\n",
            "Epoch [73/100], Training Loss: 1.2646, Validation Loss: 1.6359830276500544, Validation Accuracy: 0.5239\n",
            "Epoch [74/100], Training Loss: 1.2275, Validation Loss: 1.636401900172939, Validation Accuracy: 0.5220\n",
            "Epoch [75/100], Training Loss: 1.2278, Validation Loss: 1.6373512921248667, Validation Accuracy: 0.5220\n",
            "Epoch [76/100], Training Loss: 1.2103, Validation Loss: 1.6378993212118658, Validation Accuracy: 0.5239\n",
            "Epoch [77/100], Training Loss: 1.1702, Validation Loss: 1.628355548932002, Validation Accuracy: 0.5296\n",
            "Epoch [78/100], Training Loss: 1.2369, Validation Loss: 1.6281254827623537, Validation Accuracy: 0.5315\n",
            "Epoch [79/100], Training Loss: 1.2011, Validation Loss: 1.627180648273265, Validation Accuracy: 0.5328\n",
            "Epoch [80/100], Training Loss: 1.2525, Validation Loss: 1.6330730117989716, Validation Accuracy: 0.5315\n",
            "Epoch [81/100], Training Loss: 1.2723, Validation Loss: 1.63174951781888, Validation Accuracy: 0.5296\n",
            "Epoch [82/100], Training Loss: 1.2762, Validation Loss: 1.6265698713663768, Validation Accuracy: 0.5356\n",
            "Epoch [83/100], Training Loss: 1.1750, Validation Loss: 1.630830444527801, Validation Accuracy: 0.5302\n",
            "Epoch [84/100], Training Loss: 1.3110, Validation Loss: 1.6279395190921762, Validation Accuracy: 0.5313\n",
            "Epoch [85/100], Training Loss: 1.2044, Validation Loss: 1.6275062222452559, Validation Accuracy: 0.5333\n",
            "Epoch [86/100], Training Loss: 1.2629, Validation Loss: 1.6331675736861822, Validation Accuracy: 0.5237\n",
            "Epoch [87/100], Training Loss: 1.2173, Validation Loss: 1.635046535695093, Validation Accuracy: 0.5233\n",
            "Epoch [88/100], Training Loss: 1.2852, Validation Loss: 1.631396180779271, Validation Accuracy: 0.5268\n",
            "Epoch [89/100], Training Loss: 1.2065, Validation Loss: 1.630088014715522, Validation Accuracy: 0.5307\n",
            "Epoch [90/100], Training Loss: 1.2579, Validation Loss: 1.6316130746751143, Validation Accuracy: 0.5300\n",
            "Epoch [91/100], Training Loss: 1.2793, Validation Loss: 1.6303233698274961, Validation Accuracy: 0.5248\n",
            "Epoch [92/100], Training Loss: 1.2561, Validation Loss: 1.6284514404612886, Validation Accuracy: 0.5352\n",
            "Epoch [93/100], Training Loss: 1.1724, Validation Loss: 1.625687846065273, Validation Accuracy: 0.5332\n",
            "Epoch [94/100], Training Loss: 1.1741, Validation Loss: 1.6283075731886913, Validation Accuracy: 0.5330\n",
            "Epoch [95/100], Training Loss: 1.2650, Validation Loss: 1.6365440992208629, Validation Accuracy: 0.5244\n",
            "Epoch [96/100], Training Loss: 1.2416, Validation Loss: 1.6390220025587363, Validation Accuracy: 0.5172\n",
            "Epoch [97/100], Training Loss: 1.2016, Validation Loss: 1.6329789493210922, Validation Accuracy: 0.5257\n",
            "Epoch [98/100], Training Loss: 1.2291, Validation Loss: 1.6310514846497033, Validation Accuracy: 0.5281\n",
            "Epoch [99/100], Training Loss: 1.2619, Validation Loss: 1.6288359517881856, Validation Accuracy: 0.5291\n",
            "Epoch [100/100], Training Loss: 1.2120, Validation Loss: 1.639870277523289, Validation Accuracy: 0.5192\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torchvision.transforms as transforms\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def predict_image(model, image_path, transform):\n",
        "    # Load and preprocess the image\n",
        "    image = Image.open(image_path)\n",
        "    image_tensor = transform(image).unsqueeze(0)  # Add batch dimension\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")  # Get the available device\n",
        "\n",
        "    # Move the input tensor to the appropriate device\n",
        "    image_tensor = image_tensor.to(device)\n",
        "\n",
        "    # Set the model to evaluation mode\n",
        "    model.eval()\n",
        "\n",
        "    # Move the model to the appropriate device\n",
        "    model = model.to(device)\n",
        "\n",
        "    # Perform the prediction\n",
        "    with torch.no_grad():\n",
        "        outputs = model(image_tensor)\n",
        "        _, predicted = torch.max(outputs, 1)\n",
        "        predicted_class = predicted.item()\n",
        "\n",
        "    # Display the image and predicted class\n",
        "    plt.imshow(image)\n",
        "    plt.axis('off')\n",
        "    plt.title(f'Predicted class: {predicted_class}')\n",
        "    plt.show()\n"
      ],
      "metadata": {
        "id": "aTn3iuyg7vWB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "EMOTIONS = ['angry', 'disgusted', 'fearful', 'happy', 'sad', 'surprised', 'neutral']"
      ],
      "metadata": {
        "id": "UdxLc62h-NcB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "image = \"/content/drive/MyDrive/COSC5470/angry2.jpeg\"\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((48, 48)),\n",
        "    transforms.Grayscale(),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5,), (0.5,))\n",
        "])\n",
        "predict_image(model, image, transform)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 428
        },
        "id": "zbR4z92k7ygF",
        "outputId": "5bbd379a-672d-4642-e18e-e791232309f9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.4"
    },
    "orig_nbformat": 4,
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}